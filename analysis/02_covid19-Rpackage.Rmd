---
title: "tidycovid19 Rpackage"
author: "LJ"
date: "10/4/2020"
output: html_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  warning = FALSE, message = FALSE,
  collapse = TRUE,
  comment = "#>")
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(tidyverse))
theme_set(theme_light())
```

## The tidycovid19 Rpackage

The `tidycovid19` R package created by [Joachim Gassen](https://github.com/joachim-gassen/tidycovid19).  pulls date from various sources and offers lots of data frames that combines the current update data together with interventions and financial aid provided for each country.  It is a good tool to analyse time series data.  It also provides a tool for graphics as well.  The purpose of this notebook is to do some explorations of its functions and applications.

## Loading the package and observation.  

```{r, include = FALSE}
# remotes::install_github("joachim-gassen/tidycovid19")
library(tidycovid19)
library(tidyverse)

```

Let's see the functions and datasets that it may contain.

```{r}
ls("package:tidycovid19") %>% 
  tibble::enframe() %>% 
  select(-name) %>% 
  rename(func = value) %>% 
  slice(2:n()) %>% 
  mutate(id = row_number()) %>% 
  select(id, func)
  
```

The functions in the package are used to download the data from various sources.  I will explain the first four.

 a. The _download_acaps_npi_data_ extracts the informationf from [ACAPS](https://www.acaps.org/covid19-government-measures-dataset) and it contains data regarding government measures taken in place to avoid the spread of the virus such as lockdowns and social distancing.
 
 b. The _download_google_trends_data_ contains the data from Google Trends searches with the term "Coronavirus."  It can help see the public attention the virus and the measures taken in each country to curve it.
 
 c. The _download_jhu_csse_covid19_data_ is the most influential dataset on the subject aggregating data per country. This function extracts the updated information of the pandemic.
 
 d. The _download_merged_data()_ downloads all data sources and creates a merged country-day panel sample.
 
## Exploring the datasets

```{r}
library(tidycovid19)
```


Let'd check the google trends data.

```{r}
gtrends <- download_google_trends_data(cached = TRUE)
```

```{r}
gtrends %>% 
  glimpse()
```


```{r}
merged_df <- download_merged_data(cached = FALSE)
```


```{r}
merged_df %>% 
  glimpse()
```

```{r}
merged_df %>% 
  skimr::skim()
```

Let's see the lockdown data for Spain

```{r}
merged_df %>% 
  filter(str_detect(country, "Spain")) %>% 
  select(date, soc_dist) %>% 
  head(10)
```

The columns regarding NPI (non-pharmaceutical intervention) contain a number that I am having a hard time to decipher.  After checking the source data for NPI measures [found in this excel file from the ACAPS website and described in detail](https://www.acaps.org/sites/acaps/files/resources/files/20200409_acaps_-_covid-19_goverment_measures_dataset_v6.xlsx), I see that the numbers in those columns (soc_dist, lockdown, etc.) refer to the number of measures implemented and active in those countries.  For example, in Spain the first NPI measure taken was a Full lockdown measure on 202-03-13, hence the number 1.  Then on the 16th, 3 days later, a second measure was implemented regarding a Partial lockdown regading travel of workers in essential businesses and activities.  The numbers are cummulative.  It will be interesting to see whether these numbers decrease the numbers some measures start being lifted.  

In the next extract we can see the latest information regarding Spain where 6 measures are already in place.  


```{r}
merged_df %>% 
  filter(str_detect(country, "Spain")) %>% 
  select(country, date, soc_dist) %>% 
  tail()
```


## Counting the cummulative deaths per country

In [this other website](https://kieranhealy.org/blog/archives/2020/03/21/covid-19-tracking/) the author is doing a manual (and remarkable) work in curating by hand a dataset of the Coronavirus so he can do some analysis and visuals.  One of the things he does is calculating the cummulative number of deaths per country.  I will try to do the same thing using the datasets provided by the tidycovid package.  

It seems that the confirmed variable in the merged_df dataset refers to cummulative cases.  

```{r}
merged_df %>% 
  select(date, country, confirmed, deaths ) %>% 
  filter(str_detect(country, "China"))
```

## Augmenting the dataset


I will create an augmented merged data frame so that I can see the number of cases per day, and change the date label factor into English for consistency.

I will include a column for the number of days elapsed since the beginning of the pandemic tracking in Januray (2020-01-22)


```{r}
merged_aug <- merged_df %>% 
  mutate(c_cases = case_when(
            confirmed - lag(confirmed) < 0 ~ confirmed,
            TRUE ~ confirmed - lag(confirmed)),
         d_cases = case_when(
            deaths - lag(deaths) < 0 ~ deaths,
            TRUE ~ deaths - lag(deaths)),
         r_cases = case_when(
            recovered - lag(recovered) < 0 ~ recovered,
            TRUE ~ recovered - lag(recovered)),
         day_name = lubridate::wday(date, label = TRUE, abbr = FALSE,
  week_start = getOption("lubridate.week.start", 1)),
         day_name = as_factor(day_name),
         day_name = recode(day_name,
                           lunes = "Monday",
                           martes = "Tuesday",
                           miércoles = "Wednesday",
                           jueves = "Thursday",
                           viernes = "Friday",
                           sábado = "Saturday",
                           domingo = "Sunday"
                           ),
        days_elapsed = date - min(date)
  ) %>% 
  select(country, iso3c, region, date, days_elapsed, day_name, c_cases, confirmed, d_cases, deaths, r_cases, recovered, everything())

```


Some comments on the table above.  The data from the packages has information on the cummulative number of confirmed , deaths and recovered  cases.  I needed to include columns to see the number of each cases per day.  In order to avoid negative number of cases due to the sequential order of the countries (for example, for the earliest day in USA the number confirmed cases was about -400 since the previous row of data was the latest date in Uruguay.)

For that, I included a condition using `case_when()`.  That made the formula a bit verbose, but for the moment it does the trick.



```{r}
merged_aug %>% glimpse()
```

The following code will show the latest data for one country only.

```{r}
# Write the name of the country to search for inside the quotes
country_name <- "Spain"
merged_aug %>% 
  filter(str_detect(country, regex(country_name, ignore_case = TRUE))) %>% 
  tail(1) %>% 
  mutate_all(as.character) %>% 
  pivot_longer(cols = country:timestamp,
               names_to = "variable",
               values_to = "value")
```

## Graphs

### Evolution evolution of daily cases in a country

```{r}
# Country selected in variable country_name
merged_aug %>% 
  filter(str_detect(country, regex(country_name, ignore_case = TRUE)),
         deaths > 0) %>% 
  select(date, country, c_cases, d_cases, r_cases) %>% 
  pivot_longer(cols = ends_with("_cases"), names_to = "type_cases", values_to = "value") %>% 
  ggplot(aes(date, value, colour = type_cases)) +
   # geom_line() +
   geom_smooth() +
   facet_wrap(~ type_cases, nrow = 3, scales = "free_y") +
   labs(title = glue::glue("Daily cases in {country_name}")) +
   theme_minimal()

```


### Evolution evolution of daily cases in a region

```{r}
region_name <- "Europe"

merged_aug %>% 
  filter(str_detect(region, regex(region_name, ignore_case = TRUE)),
         confirmed != 0) %>% 
  select(date, region, c_cases, d_cases, r_cases) %>% 
  group_by(date, region) %>% 
  summarise(c_sum = sum(c_cases),
            d_sum = sum(d_cases),
            r_sum = sum(r_cases)) %>%  
  ungroup() %>% 
  pivot_longer(cols = ends_with("_sum"), names_to = "sum_cases", values_to = "value") %>% 
  ggplot(aes(date, value, colour = sum_cases)) +
   geom_line() +
   geom_smooth() +
   facet_wrap(~ sum_cases, nrow = 3, scales = "free_y") +
   labs(title = glue::glue("Cases in {region_name}"))

```




 
 



